# Silent-Speech-Sleuth (S3)

A few weeks ago, La Liga hired a professional lip reader to decide whether Jude Bellingham called Mason Greenwood a “rapist” after the two players clashed during a football (not soccer) match.
Now I am not going to look much into the incident, instead what I am going to try to build a deep learning model that is able to read lips becouse, not many of us can affor a pro lip reader.

Lip reading, a skill crucial for those with hearing impairments, has long been a challenging task due to its complexity and nuances. However, with the advent of advanced technologies like LipNet, a deep learning model designed to interpret lip movements, there is newfound hope for enhanced communication accessibility. LipNet showcases the potential of artificial intelligence in bridging communication gaps and empowering individuals with hearing impairments to engage more fully in conversations. As we delve deeper into the realm of assistive technologies, LipNet stands as a promising tool, offering a glimpse into a future where communication barriers are minimized, and inclusivity thrives.

I'll be using a range of technologies; OpenCV to read our videos and TensorFlow to build the model.
